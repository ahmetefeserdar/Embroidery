# Automated Segmentation for Directionality-Aware Embroidery

This project focuses on automating the image segmentation process required for generating directionality-aware embroidery patterns, building upon the streamline-based embroidery generation technique presented by Liu et al. (2023). The goal is to take an input image and automatically produce layered, geometrically accurate region descriptions suitable for creating complex, textured embroidery designs.

Learn more about the underlying embroidery generation method at the original project page: [Directionality-Aware Design of Embroidery Patterns](https://desmondlzy.me/publications/embroidery/).

_Directionality-Aware Design of Embroidery Patterns_. Computer Graphics Forum (Eurographics 2023); Liu Zhenyuan, Michal Piovarči, Christian Hafner, Raphaël Charrondière, Bernd Bickel

## Notice!

This code is a **research prototype** developed as part of a thesis project. It focuses specifically on the segmentation aspect. While functional for the examples tested, it may not be fully robust, optimized, or extensively documented for all use cases. The embroidery generation part relies on the code provided by Liu et al.

## Workflow Overview

The process involves two main stages (and corresponding scripts):

1.  **Segmentation (`segmentation.py`):**
    * Takes an input image (e.g., `.jpg`).
    * Applies the hierarchical segmentation algorithm (SLIC + RAG Merging based on Lab color, PCA, gradients).
    * Generates level-based JSON files (e.g., `imagename_labelme_L0.json`, `imagename_labelme_L1.json`, ...) describing the segmented regions, their hierarchy, and direction hints.
    * Outputs segmentation preview images.
2.  **Embroidery Generation (`run_patches.py` -):**
    * Takes the level-based JSON files generated by the segmentation script.
    * Parses the JSONs to extract region boundaries, colors, density, and direction information using the `common.parse_example` module from the original embroidery project.
    * Uses the `embroidery.pipeline.main_pipeline` function from the original project to generate streamlines (stitch paths) for each region.
    * Generates a combined preview image of the final embroidery pattern.

## Environment Setup

The code requires Python and several dependencies. Installation in a virtual environment using `conda` is recommended.

1.  **Create Environment:**
    Use the provided `environment.yml` file (or `environment-arm64.yml` for macOS ARM systems) to create the environment:
    ```bash
    # For standard systems (Windows, Linux, macOS Intel)
    conda env create -f environment.yml

    # For macOS ARM (M1/M2/M3) or other arm64 systems
    conda env create -f environment-arm64.yml
    ```
2.  **Activate Environment:**
    ```bash
    conda activate embroidery_env # Or whatever you name the environment (I named it emb2)
    ```

## Running the Scripts

The primary scripts likely reside in an `examples` or main directory.

1.  **Run Segmentation:**
    * Modify the `IMG` variable inside the segmentation script (`segmentation.py`) to point to your desired input image.
    * Adjust segmentation parameters (`N_SEGMENTS`, `THRESH`, `GAMMA`, etc.) as needed for your image.
    * Run the script
    * This will generate `*_labelme_L*.json` files in the `data` directory and preview images in `output_previews`.

2.  **Run Embroidery Generation:**
    * Modify the `task_name_base` variable inside the embroidery generation script (`run_patches.py`) to match the base name of your image (e.g., "sky").
    * Set `SKIP_LEVEL_0` to `True` or `False` depending on whether you want to include the background layer stitches.
    * Run the script
    * This will process the corresponding JSON files, generate intermediate plots (if enabled in `main_pipeline`), save a combined preview (`preview_merged.png`/`.svg`) in `output/{task_name_base}_merged`, and display the preview plot.

## Using Your Own Images

1.  Place your image (e.g., `my_image.jpg`) in the `data` folder.
2.  Run the **segmentation script**, making sure the `IMG` variable points to your image (`data/my_image.jpg`). Tune parameters as needed. This creates `data/my_image_labelme_L*.json`.
3.  Run the **embroidery generation script**, setting `task_name_base = "my_image"`. Adjust `SKIP_LEVEL_0` if desired. This generates the preview in `output/my_image_merged`.

## Citing the Embroidery Generation Method

If you use the underlying embroidery generation pipeline in your work, please cite the original paper:

```bibtex
@article{SupervisorPaper2023,
  author    = {Liu, Zhenyuan and Piovar\c{c}i, Michal and Hafner, Christian and Charrondi\`{e}re, Rapha\"{e}l and Bickel, Bernd},
  title     = {Directionality-Aware Design of Embroidery Patterns},
  journal   = {Computer Graphics Forum},
  volume    = {42},
  number    = {2},
  year      = {2023},
  publisher = {The Eurographics Association and John Wiley \& Sons Ltd.},
  doi       = {10.1111/cgf.14770}
}
